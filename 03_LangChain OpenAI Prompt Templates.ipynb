{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938556af-541a-4286-bf98-ef139125a078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9faf781b-16dd-4f62-9922-82ee6940461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.cache import InMemoryCache\n",
    "# langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae7b4afa-75a0-4335-89fe-7e38f6686e08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dadb86a6-64c8-4f9d-9a67-13368fd9d107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open('./openai_key.txt')\n",
    "api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab49119-15b2-47bb-910a-6f99ef888de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=api_key)\n",
    "chat = ChatOpenAI(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a28141e-5ead-44e4-8874-04ad7d672462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of France is Paris.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM\n",
    "llm(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de617a",
   "metadata": {},
   "source": [
    "## Large Language Model Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3713a6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"What is the capital of {country}?\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"country\"])\n",
    "prompt.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd323cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a fact about physics for a senior student.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factTemplate = \"Tell me a fact about {topic} for a {level} student.\"\n",
    "variables = [\"topic\", \"level\"]\n",
    "multi_input_prompt = PromptTemplate(template=factTemplate, input_variables=variables)\n",
    "\n",
    "multi_input_prompt.format(topic=\"physics\", level=\"senior\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e8d68fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One fact about physics for a college student is that the speed of light in a vacuum is approximately 299,792,458 meters per second, or about 670,616,629 miles per hour. This fundamental constant is a cornerstone of Einstein's theory of relativity and has important implications for the behavior of matter and energy in our universe.\n"
     ]
    }
   ],
   "source": [
    "print(llm(multi_input_prompt.format(topic=\"physics\", level=\"college\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893402e4",
   "metadata": {},
   "source": [
    "## Chat Model Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab3fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate,AIMessagePromptTemplate,SystemMessagePromptTemplate,HumanMessagePromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80856285",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are an AI recipe assistant that specializes in {dietary_preference} dishes that can be prepared in {cooking_time}.\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "587ff28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"{recipe_request}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74dd3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ebe569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cooking_time', 'dietary_preference', 'recipe_request']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8562580",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = chat_prompt.format_prompt(cooking_time=\"30 minutes\", \n",
    "    dietary_preference=\"vegetarian\", \n",
    "    recipe_request=\"How to make a taco\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd90330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chat_result = chat(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d269090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a simple and delicious vegetarian taco recipe that can be prepared in just 30 minutes:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup cooked black beans\n",
      "- 1 cup corn kernels (fresh or frozen)\n",
      "- 1 bell pepper, diced\n",
      "- 1 small red onion, diced\n",
      "- 2 cloves garlic, minced\n",
      "- 1 tablespoon olive oil\n",
      "- 1 tablespoon taco seasoning\n",
      "- Salt and pepper to taste\n",
      "- 8 small tortillas\n",
      "- Toppings of your choice: shredded lettuce, diced tomatoes, avocado slices, salsa, sour cream, etc.\n",
      "\n",
      "Instructions:\n",
      "1. In a large skillet, heat the olive oil over medium heat. Add the diced bell pepper, red onion, and minced garlic. Saut√© for about 5 minutes or until the vegetables are slightly softened.\n",
      "\n",
      "2. Add the cooked black beans and corn kernels to the skillet. Stir in the taco seasoning, salt, and pepper. Cook for another 5 minutes, stirring occasionally, until the beans and corn are heated through.\n",
      "\n",
      "3. In the meantime, warm the tortillas in another skillet or in the microwave according to the package instructions.\n",
      "\n",
      "4. Assemble the tacos by spooning the black bean and corn mixture onto each tortilla. Top with your desired toppings such as shredded lettuce, diced tomatoes, avocado slices, salsa, and sour cream.\n",
      "\n",
      "5. Serve the tacos immediately and enjoy!\n",
      "\n",
      "Feel free to customize your tacos with additional toppings or ingredients such as cheese, cilantro, lime juice, or hot sauce. Enjoy your homemade vegetarian tacos!\n"
     ]
    }
   ],
   "source": [
    "print(chat_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142415f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
