{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64959efd",
   "metadata": {},
   "source": [
    "# Lanchain Mistral Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "254ea1fe-8746-4c51-9d8e-c4c1aaa1eb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9faf781b-16dd-4f62-9922-82ee6940461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "\n",
    "cacheType = 'in_memory'\n",
    "\n",
    "if cacheType == 'in_memory':\n",
    "    set_llm_cache(InMemoryCache())\n",
    "elif cacheType == 'sqlite':\n",
    "    set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511ab0b-6bc3-4b5f-b627-0e28662a0f0a",
   "metadata": {},
   "source": [
    "# Setup LLM - Google Flan T5 Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb39b279-ff74-4de0-89b6-9c33e3f8e7dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "\n",
    "chat = ChatMistralAI(endpoint=\"http://192.168.68.76:1234\", \n",
    "                     mistral_api_key=\"not-needed\", \n",
    "                     temprature=0,\n",
    "                    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ac7013d-9c1a-41c5-a3ad-d3512f9260b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Import chat templates\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8c160a4-2506-4dda-83d2-c29d54b0949b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"1. Introduction to Nike Shoes: Brief history and popularity\\n2. Types of Nike Shoes: Running, Basketball, Training, and Lifestyle\\n3. Top Nike Shoes Models: Air Jordan, Air Force 1, Pegasus, etc.\\n4. Design and Technology: Innovations in materials, cushioning, and fit\\n5. Customization: NikeID and other personalization options\\n6. Collaborations: Sneakerheads favorite partnerships with artists, musicians, and athletes\\n7. Fashion Trends: How Nike shoes fit into current styles and streetwear culture\\n8. Sustainability: Nike's efforts towards more eco-friendly production methods\\n9. Buying and Collecting: Tips for purchasing authentic shoes and starting a collection\\n10. Conclusion: The enduring appeal of Nike shoes and their impact on popular culture.\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template1 = 'Give me a simple bullet point outline for a blog post on:\\n {topic}'\n",
    "first_prompt = ChatPromptTemplate.from_template(template1)\n",
    "hmsg = first_prompt.format_prompt(topic='nike shoes').to_messages()\n",
    "\n",
    "\n",
    "chat.invoke(hmsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486dcf4-23e8-4ffb-a5fa-781f7c9f91d7",
   "metadata": {},
   "source": [
    "## HF Instructor Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54e2518e-70b5-46f9-9150-7c6ebee2bad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings, HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cuda:1\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embedding = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97e058-a20b-488c-ab7b-952f580fbaaa",
   "metadata": {},
   "source": [
    "# Load Multiple documents and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eab49119-15b2-47bb-910a-6f99ef888de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load all files in dirl\n",
    "loader = DirectoryLoader('./new_articles/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c721f-3fc5-4a6d-a39b-231c85ab1e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7729c05c-812b-4389-825e-89357f0c9a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "# Options are - stuff, refine, map_reduce\n",
    "chain = load_summarize_chain(llm=chat, chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dff13081-841f-4348-96bd-8d5855e28b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88d4db66bbc4b6e8589537767444178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.04M [00:02<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bc42c6f1c64c3f92a37daf3d1b721b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f0ef72265e470f9c42dc7e732067eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd10ff4822434a42a601ebcf310ed1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pandoâ€™s global sales, marketing and delivery capabilities.\\n\\n\"We will not expand into new industries or adjacent product areas,\" he told TechCrunch in an email interview. \"Great talent is the foundation of the business â€” we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.\"\\n\\nPando was co-launched by Jayakrishnan and Abhijeet Manohar, who previously worked together at iDelivery, an India-based freight tech marketplace â€” and their first startup. The two saw firsthand manufacturers, distributors and retailers were struggling with legacy tech and point solutions to understand, optimize and manage their global logistics operations â€” or at least, thatâ€™s the story Jayakrishnan tells.\\n\\n\"Supply chain leaders were trying to build their own tech and throwing people at the problem,\" he said. \"This caught our attention â€” we spent months talking to and building for enterprise users at warehouses, factories, freight yards and ports and eventually, in 2018, decided to start Pando to solve for global logistics through a software-as-a-service platform offering.\"\\n\\nThereâ€™s truth to what Jayakrishnanâ€™s expressing about pent-up demand. According to a recent McKinsey survey, supply chain companies had â€” and have â€” a strong desire for tools that deliver greater supply chain visibility. Sixty-seven percent of respondents to the survey say that theyâ€™ve implemented dashboards for this purpose, while over half say that theyâ€™re investing in supply chain visibility services more broadly.\\n\\nPando aims to meet the need by consolidating supply chain data that resides in multiple silos within and outside of the enterprise, including data on customers, suppliers, logistics service providers, facilities and product SKUs. The platform provides various tools and apps for accomplishing different tasks across freight procurement, trade and transport management, freight audit and payment and document management, as well as dispatch planning and analytics.\\n\\nCustomers can customize the tools and apps or build their own using Pandoâ€™s APIs. This, along with the platformâ€™s emphasis on no-code capabilities, differentiates Pando from incumbents like SAP, Oracle, Blue Yonder and E2Open, Jayakrishnan asserts.\\n\\n\"Pando comes pre-integrated with leading enterprise resource planning (ERPs) systems and has ready APIs and a professional services team to integrate with any new ERPs and enterprise systems,\" he added. \"Pandoâ€™s no-code capabilities enable business users to customize the apps while maintaining platform integrity â€” reducing the need for IT resources for each customization.\"\\n\\nPando also taps algorithms and forms of machine learning to make predictions around supply chain events. For example, the platform attempts to match customer orders with suppliers, customers through the \"right\" channel (in terms of aspects like cost and carbon footprint) and fulfillment strategy (e.g. mode of freight, carrier, etc.). Beyond this, Pando can detect anomalies among deliveries, orders and freight invoices and anticipate supply chain risk given demand and supply trends.\\n\\nPando isnâ€™t the only vendor doing this. Altana, which bagged $100 million in venture capital last October, uses an AI system to connect to and learn from logistics and business-to-business data â€” creating a shared view of supply chain networks. Everstream, another Pando rival, offers its own dashboards for data analysis, integrated with existing ERP, transportation management and supplier relationship management systems.\\n\\nBut Pando has a compelling sales pitch, judging by its momentum. The company counts Fortune 500 manufacturers and retailers â€” including P&G, J&J, Valvoline, Castrol, Cummins, Siemens, Danaher and Accuride â€” among its customer base. Since the startupâ€™s Series A in 2020, revenue has grown 8x while the number of customers has increased 5x, Jayakrishnan said.\\n\\nAsked whether he expects expansion to continue well into the future, given the signs of potential trouble on the horizon, Jayakrishnan seemed fairly optimistic. He pointed to a Deloitte survey that found that more than 70% of manufacturing companies have been impacted by supply chain disruptions in the past year, with 90% of those companies experiencing increased costs and declining productivity.\\n\\nThe result of those major disruptions? The digital logistics market is estimated to climb to $46.5 billion by 2025, per Markets and Markets â€” up from $17.4 billion in 2019. Crunchbase reports that investors poured more than $7 billion in seed through growth-stage rounds globally for supply chain-focused startups from January to October 2022, nearly eclipsing 2021â€™s record-setting levels.\\n\\n\"Pando has a strong balance sheet and profit and loss statement, with an eye on profitable growth,\" Jayakrishnan said. \"Weâ€™re are scaling operations in North America, Europe and India with marquee customer wins and a network of strong partners â€¦ Pando is well-positioned to ride this growth wave, and drive supply chain agility for the 2030 economy.\"', metadata={'source': 'new_articles\\\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'})],\n",
       " 'output_text': 'Pando, a startup providing fulfillment management tech for the supply chain sector, raised $30 million in Series B funding, totalling $45 million. Iron Pillar and Uncorrelated Ventures led, with existing investors participating. New funds will expand sales, marketing, and delivery capabilities without entering new industries or products. Co-founded by Nitin Jayakrishnan and Abhijeet Manohar, Pando aims for greater supply chain visibility, consolidating data silos. Their platform offers tools for freight procurement, transport management, document management, and analytics, focusing on no-code capabilities and APIs for customization. Pando serves Fortune 500 manufacturers and retailers, anticipates growth in $46.5 billion digital logistics market by 2025, with $7 billion+ invested in supply chain startups from Jan-Oct 2022.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke([documents[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2768f32-2298-476c-af55-7307eefdc23b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pando, a supply chain visibility platform founded by Nitin Jayakrishnan and Abhijeet Manohar, raised $30 million in Series B funding led by Iron Pillar and Uncorrelated Ventures. The company aims to expand globally, hire top talent, and explore partnerships or acquisitions. With increasing demand for greater supply chain visibility, Pando consolidates data from various silos using no-code tools and apps for logistics management. Its machine learning algorithms predict and optimize fulfillment strategies for clients like P&G and J&J. The digital logistics market is projected to reach $46.5 billion by 2025 due to disruptions and investments, with Pando expanding in North America, Europe, and India.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents([documents[0]])\n",
    "\n",
    "chain.run(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94000a34-11a0-44bf-b1bc-a48cd11d97b4",
   "metadata": {},
   "source": [
    "## Pydantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad3f1471-deb6-46c2-9124-0a0183f01071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6d45a24-5e70-413a-8d88-9bea689dd372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel(BaseModel):\n",
    "    question: str = Field(description=\"Question\")\n",
    "    answer: str = Field(description=\"Answer to question\")\n",
    "\n",
    "class QADocument(BaseModel):\n",
    "    metadata: dict = None\n",
    "    original: str= None\n",
    "    source: str = Field(description=\"Metdata for the source document\")\n",
    "    summary: str = Field(description=\"Original content being processed\")\n",
    "    items: List[QAModel] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ade5de0-2305-48c4-a4c9-1fb8a6316cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def creat_document_lc(page_content:str, metadata:dict):\n",
    "    return Document(page_content=page_content, metadata=metadata)\n",
    "\n",
    "def format_page_content(response: QAModel):\n",
    "    return f\"\"\"Question: {response.question}\\nAnswer: {response.answer}\"\"\"\n",
    "\n",
    "def format_page_metadata(result: QADocument):\n",
    "    qaCount = 0 if not result.items else len(result.items)\n",
    "    return {\n",
    "        'source': result.source,\n",
    "        'qaCount': qaCount\n",
    "        # Additional properties here if necessary\n",
    "    }\n",
    "\n",
    "def export_document(result: QADocument) -> list :\n",
    "    metadata = format_page_metadata(result)\n",
    "    final_str = f\"***Summary***:\\n\\n{result.summary}\\n\\n***Possible QA***\\n\"\n",
    "    \n",
    "    for item in result.items:\n",
    "        qa = format_page_content(item)\n",
    "        final_str += f\"\\n{qa}\\n\"\n",
    "    \n",
    "    final_str += f\"\\n***Original***\\n\\n{result.original}\"\n",
    "    \n",
    "    doc = creat_document_lc(page_content=final_str, metadata=metadata)\n",
    "    return doc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc6156af-c729-4de3-8946-ae56ea4924c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"\"\"{request}\\n{format_instructions}\"\"\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d2ef713-5194-4938-82f1-187763a3975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_request_for_questions(source_name: str, summary: str):\n",
    "    q_template1 = f\"\"\"Create a few questions and answers covering the below text starting and ending with ### :\n",
    "    ###{summary}###\n",
    "\n",
    "    Text metadata to be included in results:\n",
    "    source: {source_name}\n",
    "    summary: [This should be the text provided igenerate_request_for_questionsn above with ###]\n",
    "    original: [This can be left blank]\n",
    "    metadata: [This can be left blank]\n",
    "    \"\"\"\n",
    "\n",
    "    request = chat_prompt.format_prompt(request=q_template1,\n",
    "                                       format_instructions=parser.get_format_instructions()).to_messages()\n",
    "    \n",
    "    return request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df409ce9-c0f2-4cd3-8a33-126d9deeaaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=QADocument)\n",
    "# parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c8d8213-89c8-46c8-8558-1b011130fe82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will genrate a Summary -> Generate Questions -> Create new document wrapper\n",
    "def process_document(document: Document) -> Document:\n",
    "    print(\"Processing document: \", document.metadata['source'])\n",
    "    \n",
    "    try:\n",
    "        # Create summary\n",
    "        doc_name = document.metadata['source']\n",
    "        summary_resp = chain.run([document])\n",
    "\n",
    "        # Create request for questions\n",
    "        question_request = generate_request_for_questions(source_name=doc_name, summary=summary_resp)\n",
    "        question_response = chat(question_request, temperature=0.0)\n",
    "        parsed_questions_qadoc = parser.parse(question_response.content)\n",
    "\n",
    "        # Set core details\n",
    "        parsed_questions_qadoc.original = document.page_content\n",
    "\n",
    "        # Generate new doc\n",
    "        final_doc = export_document(parsed_questions_qadoc)\n",
    "\n",
    "    except Exception as error:\n",
    "        # handle the exception\n",
    "        print(\"An exception occurred:\", error)\n",
    "    \n",
    "    print(\"Done processing document: \", document.metadata['source'])\n",
    "    \n",
    "    return final_doc\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d913c8-a980-4d73-8de3-f83a065ef015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17cef2-57c0-4a7c-82da-bb86521f7535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd792c16-4d4a-422e-b29c-4fee94a138c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question_request' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# question_request[0].content\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m chat(question_request[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'question_request' is not defined"
     ]
    }
   ],
   "source": [
    "# question_request[0].content\n",
    "chat(question_request[1].content, temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3145cf6-e630-4dc4-9a7d-7c7f10a309df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "document = documents[1]\n",
    "\n",
    "# Create summary\n",
    "doc_name = document.metadata['source']\n",
    "summary_resp = chain.run([document])\n",
    "\n",
    "# Create request for questions\n",
    "question_request = generate_request_for_questions(source_name=doc_name, summary=summary_resp)\n",
    "question_response = chat(question_request, temperature=0.0)\n",
    "parsed_questions_qadoc = parser.parse(question_response.content)\n",
    "\n",
    "# Set core details\n",
    "parsed_questions_qadoc.original = document.page_content\n",
    "\n",
    "# Generate new doc\n",
    "final_doc = export_document(parsed_questions_qadoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9214b0da-ae87-4082-971b-96d03807d851",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Summary***:\n",
      "\n",
      "The Writers Guild of America (WGA) is currently on strike due to various demands including better working conditions and improved streaming residuals. One contentious issue is the use of AI in writers' rooms, with the WGA proposing that they should not be required to adapt or consider AI-generated output as their work. The Alliance of Motion Picture and Television Producers (AMPTP) has refused to engage with this proposal, instead offering annual meetings to discuss technological advances. While current text-generating algorithms like ChatGPT can produce responses based on desired outputs, they cannot create nuanced, entertaining dialogue or navigate the complexities of human collaboration. Some writers see potential for AI to facilitate brainstorming sessions but worry about its impact on working conditions and fair compensation. The legal status of copyrightable AI-generated content is also unclear, potentially putting studios at risk. The primary concerns for the WGA remain fair compensation and adequate resources for human writers.\n",
      "\n",
      "***Possible QA***\n",
      "\n",
      "Question: What is the current issue between the Writers Guild of America (WGA) and the Alliance of Motion Picture and Television Producers (AMPTP) regarding AI in writers' rooms?\n",
      "Answer: The WGA wants to be exempted from adapting or considering AI-generated output as their work, while AMPTP is offering annual meetings to discuss technological advances. The WGA is concerned about fair compensation and adequate resources for human writers, while the legal status of copyrightable AI-generated content is also unclear.\n",
      "\n",
      "Question: Why can't current text-generating algorithms like ChatGPT create nuanced, entertaining dialogue or navigate the complexities of human collaboration?\n",
      "Answer: Current text-generating algorithms like ChatGPT can produce responses based on desired outputs but cannot create nuanced, entertaining dialogue or navigate the complexities of human collaboration.\n",
      "\n",
      "Question: What are some potential impacts of AI on working conditions and fair compensation for writers?\n",
      "Answer: Some writers see potential for AI to facilitate brainstorming sessions but worry about its impact on working conditions and fair compensation.\n",
      "\n",
      "***Original***\n",
      "\n",
      "In the must-watch final season of \"Succession,\" Kendall Roy enters a conference room with his siblings. As the scene opens, he takes a seat and declares: \"Who will be the successor? Me.\"\n",
      "\n",
      "Of course, that scene didnâ€™t appear on HBOâ€™s hit show, but itâ€™s a good illustration of generative AIâ€™s level of sophistication compared to the real thing. Yet as the Writers Guild of America goes on strike in pursuit of livable working conditions and better streaming residuals, the networks wonâ€™t budge on writersâ€™ demands to regulate the use of AI in writersâ€™ rooms.\n",
      "\n",
      "\"Our proposal is that we not be required to adapt something thatâ€™s output by AI, and that the output of an AI not be considered writersâ€™ work,\" comedy writer Adam Conover told TechCrunch. \"That doesnâ€™t entirely exclude that technology from the production process, but it does mean that our working conditions wouldnâ€™t be undermined by AI.\"\n",
      "\n",
      "But the Alliance of Motion Picture and Television Producers (AMPTP) refused to engage with that proposal, instead offering a yearly meeting to discuss \"advances in technology.\"\n",
      "\n",
      "\"When we first put [the proposal] in, we thought we were covering our bases â€” you know, some of our members are worried about this, the area is moving quickly, we should get ahead of it,\" Conover said. \"We didnâ€™t think itâ€™d be a contentious issue because the fact of the matter is, the current state of the text-generation technology is completely incapable of writing any work that could be used in a production.\"\n",
      "\n",
      "The text-generating algorithms behind tools like ChatGPT are not built to entertain us. Instead, they analyze patterns in massive datasets to respond to requests by determining what is most likely the desired output. So, ChatGPT knows that \"Succession\" is about an aging media magnateâ€™s children fighting for control of his company, but it is unlikely to come up with any dialogue more nuanced than, \"Who will be the successor? Me.\"\n",
      "\n",
      "According to Ben Zhao, a University of Chicago professor and faculty lead of art anti-mimicry tool Glaze, AI advancements can be used as an excuse for corporations to devalue human labor.\n",
      "\n",
      "\"Itâ€™s to the advantage of the studios and bigger corporations to basically over-claim ChatGPTâ€™s abilities, so they can, in negotiations at least, undermine and minimize the role of human creatives,\" Zhao told TechCrunch. \"Iâ€™m not sure how many people at these larger companies actually believe what theyâ€™re saying.\"\n",
      "\n",
      "Conover emphasized that some parts of a writerâ€™s job are less obvious than literal scriptwriting but equally difficult to replicate with AI.\n",
      "\n",
      "\"Itâ€™s going and meeting with the set decoration department that says, â€˜Hey, we canâ€™t actually build this prop that youâ€™re envisioning, could you do this instead?â€™ and then you talk to them and go back and rewrite,\" he said. \"This is a human enterprise that involves working with other people, and that simply cannot be done by an AI.\"\n",
      "\n",
      "Comedian Yedoye Travis sees how AI could be useful in a writersâ€™ room.\n",
      "\n",
      "\"What we do in writersâ€™ rooms is ultimately bouncing ideas around,\" he told TechCrunch. \"Even if itâ€™s not good per se, an AI can throw together a script in however many minutes, compared to a week for human writers, and then itâ€™s easier to edit than to write.\"\n",
      "\n",
      "But even if there may be some promise for how humans can leverage this technology, he worries that studios see it merely as a way to demand more from writers over a shorter period of time.\n",
      "\n",
      "\"It says to me that theyâ€™re only concerned with things being made,\" Travis said. \"Theyâ€™re not concerned with people being paid for things being made.\"\n",
      "\n",
      "Writers are also advocating to regulate the use of AI in entertainment because it remains a legal grey area.\n",
      "\n",
      "\"Itâ€™s not clear that the work that it outputs is copyrightable, and a movie studio is not going to spend $50 to $100 million shooting a script that they donâ€™t know that they own the copyright to,\" Conover said. \"So we figured this would be an easy give for [the AMPTP], but they completely stonewalled on it.\"\n",
      "\n",
      "As the Writers Guild of America strikes for the first time since its historic 100-day action in 2007, Conover said he thinks the debate over AI technology is a \"red herring.\" With generative AI in such a rudimentary stage, writers are more immediately concerned with dismal streaming residuals and understaffed writing teams. Yet studiosâ€™ pushback on the unionâ€™s AI-related requests only further reinforces the core issue: The people who power Hollywood arenâ€™t being paid their fair share.\n",
      "\n",
      "\"Iâ€™m not worried about the technology,\" Conover said. \"Iâ€™m worried about the companies using technology, that is not in fact very good, to undermine our working conditions.\"\n"
     ]
    }
   ],
   "source": [
    "print(final_doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424821d8-e370-4e13-9dff-d62ee1c4885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through all documents\n",
    "\n",
    "enriched_documents = []\n",
    "for doc in documents:\n",
    "    enriched = process_document(document=doc)\n",
    "    enriched_documents.append( enriched )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b36f0b-ac2f-4fec-b5e9-ceae3f29ad86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enriched_documents[2].page_content[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188dd9b-4414-446a-9505-c5808d3e4ba4",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551435c1-2859-4b2b-857b-a7b9ca49ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(enriched_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbca027-af80-442e-81e7-15e8b6835094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa405f-077f-4610-9fab-f12f2ee2a31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d59db-cb9b-4bcc-87e6-f5b84370cb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "persist_dir = 'articles_db_flant5'\n",
    "\n",
    "vecordb = Chroma.from_documents(documents=texts,\n",
    "                                embedding=embedding,\n",
    "                                persist_directory=persist_dir)\n",
    "\n",
    "vecordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0e4fe-5c0f-49e9-8014-02d6a9bc86fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vecordb.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca6e7f-049a-4e5a-9da2-c5f084f90245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"Databricks Okera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70444df-cbdd-445b-8bcd-b77fe28fd1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6eedd-71d1-42c5-b14f-9c38339673e9",
   "metadata": {},
   "source": [
    "# Make Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cba8e-f15f-4aac-b11c-4cf578b8f246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                       chain_type=\"refine\",\n",
    "                                       retriever=retriever,\n",
    "                                       return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac76b7d-e4f9-47cf-a4e9-edbfd617774e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd466e-5d94-41fc-bad2-f92cb5640d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full example\n",
    "query = \"How much money did Pando raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90a2c4-c1a0-45c8-bc5b-14b9bb889668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# break it down\n",
    "query = \"What is the news about Pando?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)\n",
    "# llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd6108-c894-40b0-bb81-5bb8872cb165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"Who led the round in Pando?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d1fe3-0ffd-485c-9570-2850070b38c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What did databricks acquire?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d56d870-655c-49a9-a204-8e33083831fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What is generative ai?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d836e-9c43-47cf-870d-6249a298eb88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
