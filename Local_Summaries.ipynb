{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64959efd",
   "metadata": {},
   "source": [
    "# Lanchain OpenAI Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938556af-541a-4286-bf98-ef139125a078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = open('./openai_key.txt').read()\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254ea1fe-8746-4c51-9d8e-c4c1aaa1eb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9faf781b-16dd-4f62-9922-82ee6940461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "\n",
    "cacheType = 'in_memory'\n",
    "\n",
    "if cacheType == 'in_memory':\n",
    "    set_llm_cache(InMemoryCache())\n",
    "elif cacheType == 'sqlite':\n",
    "    set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a3313f5-24c4-49f4-9bff-5e6fdb0cfe37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set OpenAI API key and create LLM and Chat LLM. Note that key can be stored in a separate file or as an environment variable. Refer to docs.\n",
    "\n",
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97e058-a20b-488c-ab7b-952f580fbaaa",
   "metadata": {},
   "source": [
    "# Load Multiple documents and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab49119-15b2-47bb-910a-6f99ef888de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load all files in dirl\n",
    "loader = DirectoryLoader('./new_articles/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c721f-3fc5-4a6d-a39b-231c85ab1e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ac7013d-9c1a-41c5-a3ad-d3512f9260b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Import chat templates\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7729c05c-812b-4389-825e-89357f0c9a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "chain = load_summarize_chain(llm=chat, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94000a34-11a0-44bf-b1bc-a48cd11d97b4",
   "metadata": {},
   "source": [
    "## Pydantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ad3f1471-deb6-46c2-9124-0a0183f01071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e6d45a24-5e70-413a-8d88-9bea689dd372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel(BaseModel):\n",
    "    question: str = Field(description=\"Question\")\n",
    "    answer: str = Field(description=\"Answer to question\")\n",
    "\n",
    "class QADocument(BaseModel):\n",
    "    metadata: dict = None\n",
    "    original: str= None\n",
    "    source: str = Field(description=\"Metdata for the source document\")\n",
    "    summary: str = Field(description=\"Original content being processed\")\n",
    "    items: List[QAModel] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7ade5de0-2305-48c4-a4c9-1fb8a6316cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def creat_document_lc(page_content:str, metadata:dict):\n",
    "    return Document(page_content=page_content, metadata=metadata)\n",
    "\n",
    "def format_page_content(response: QAModel):\n",
    "    return f\"\"\"Question: {response.question}\\nAnswer: {response.answer}\"\"\"\n",
    "\n",
    "def format_page_metadata(result: QADocument):\n",
    "    qaCount = 0 if not result.items else len(result.items)\n",
    "    return {\n",
    "        'source': result.source,\n",
    "        'qaCount': qaCount\n",
    "        # Additional properties here if necessary\n",
    "    }\n",
    "\n",
    "def export_document(result: QADocument) -> list :\n",
    "    metadata = format_page_metadata(result)\n",
    "    final_str = f\"***Summary***:\\n\\n{result.summary}\\n\\n***Possible QA***\\n\"\n",
    "    \n",
    "    for item in result.items:\n",
    "        qa = format_page_content(item)\n",
    "        final_str += f\"\\n{qa}\\n\"\n",
    "    \n",
    "    final_str += f\"\\n***Original***\\n\\n{result.original}\"\n",
    "    \n",
    "    doc = creat_document_lc(page_content=final_str, metadata=metadata)\n",
    "    return doc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "cc6156af-c729-4de3-8946-ae56ea4924c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"\"\"{request}\\n{format_instructions}\"\"\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5d2ef713-5194-4938-82f1-187763a3975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_request_for_questions(source_name: str, summary: str):\n",
    "    q_template1 = f\"\"\"Create a few questions and answers covering the below text starting and ending with ### :\n",
    "    ###{summary}###\n",
    "\n",
    "    Text metadata to be included in results:\n",
    "    source: {source_name}\n",
    "    summary: [This should be the text provided igenerate_request_for_questionsn above with ###]\n",
    "    original: [This can be left blank]\n",
    "    metadata: [This can be left blank]\n",
    "    \"\"\"\n",
    "\n",
    "    request = chat_prompt.format_prompt(request=q_template1,\n",
    "                                       format_instructions=parser.get_format_instructions()).to_messages()\n",
    "    \n",
    "    return request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "df409ce9-c0f2-4cd3-8a33-126d9deeaaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=QADocument)\n",
    "# parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8c8d8213-89c8-46c8-8558-1b011130fe82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will genrate a Summary -> Generate Questions -> Create new document wrapper\n",
    "def process_document(document: Document) -> Document:\n",
    "    print(\"Processing document: \", document.metadata['source'])\n",
    "    \n",
    "    try:\n",
    "        # Create summary\n",
    "        doc_name = document.metadata['source']\n",
    "        summary_resp = chain.run([document])\n",
    "\n",
    "        # Create request for questions\n",
    "        question_request = generate_request_for_questions(source_name=doc_name, summary=summary_resp)\n",
    "        question_response = chat(question_request, temperature=0.0)\n",
    "        parsed_questions_qadoc = parser.parse(question_response.content)\n",
    "\n",
    "        # Set core details\n",
    "        parsed_questions_qadoc.original = document.page_content\n",
    "\n",
    "        # Generate new doc\n",
    "        final_doc = export_document(parsed_questions_qadoc)\n",
    "\n",
    "    except Exception as error:\n",
    "        # handle the exception\n",
    "        print(\"An exception occurred:\", error)\n",
    "    \n",
    "    print(\"Done processing document: \", document.metadata['source'])\n",
    "    \n",
    "    return final_doc\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "424821d8-e370-4e13-9dff-d62ee1c4885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document:  new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "Done processing document:  new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "Processing document:  new_articles\\05-03-ai-replace-tv-writers-strike.txt\n",
      "Done processing document:  new_articles\\05-03-ai-replace-tv-writers-strike.txt\n",
      "Processing document:  new_articles\\05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt\n",
      "Done processing document:  new_articles\\05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt\n",
      "Processing document:  new_articles\\05-03-checks-the-ai-powered-data-protection-project-incubated-in-area-120-officially-exits-to-google.txt\n",
      "Done processing document:  new_articles\\05-03-checks-the-ai-powered-data-protection-project-incubated-in-area-120-officially-exits-to-google.txt\n",
      "Processing document:  new_articles\\05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
      "Done processing document:  new_articles\\05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
      "Processing document:  new_articles\\05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
      "Done processing document:  new_articles\\05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
      "Processing document:  new_articles\\05-03-spawning-lays-out-its-plans-for-letting-creators-opt-out-of-generative-ai-training.txt\n",
      "Done processing document:  new_articles\\05-03-spawning-lays-out-its-plans-for-letting-creators-opt-out-of-generative-ai-training.txt\n"
     ]
    }
   ],
   "source": [
    "# Run through all documents\n",
    "\n",
    "enriched_documents = []\n",
    "for doc in documents:\n",
    "    enriched = process_document(document=doc)\n",
    "    enriched_documents.append( enriched )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "42b36f0b-ac2f-4fec-b5e9-ceae3f29ad86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'***Summary***:\\n\\nChatGPT, an AI-powered chatbot developed by OpenAI, has gained popularity for its ability to generate text in various domains. OpenAI has made significant updates to ChatGPT, including the integration of GPT-4, the latest language-writing model, and the introduction of plugins that a'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_documents[2].page_content[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188dd9b-4414-446a-9505-c5808d3e4ba4",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "551435c1-2859-4b2b-857b-a7b9ca49ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(enriched_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "fcbca027-af80-442e-81e7-15e8b6835094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='\"We will not expand into new industries or adjacent product areas,\" he told TechCrunch in an email interview. \"Great talent is the foundation of the business â€” we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.\"\\n\\nPando was co-launched by Jayakrishnan and Abhijeet Manohar, who previously worked together at iDelivery, an India-based freight tech marketplace â€” and their first startup. The two saw firsthand manufacturers, distributors and retailers were struggling with legacy tech and point solutions to understand, optimize and manage their global logistics operations â€” or at least, thatâ€™s the story Jayakrishnan tells.', metadata={'source': 'new_articles\\\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt', 'qaCount': 6})"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa405f-077f-4610-9fab-f12f2ee2a31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d67d59db-cb9b-4bcc-87e6-f5b84370cb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "persist_dir = 'articles_db2'\n",
    "\n",
    "# Embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vecordb = Chroma.from_documents(documents=texts,\n",
    "                                embedding=embedding,\n",
    "                                persist_directory=persist_dir)\n",
    "\n",
    "vecordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "83d0e4fe-5c0f-49e9-8014-02d6a9bc86fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vecordb.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f5ca6e7f-049a-4e5a-9da2-c5f084f90245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"Databricks Okera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f70444df-cbdd-445b-8bcd-b77fe28fd1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6eedd-71d1-42c5-b14f-9c38339673e9",
   "metadata": {},
   "source": [
    "# Make Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "727cba8e-f15f-4aac-b11c-4cf578b8f246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                       chain_type=\"refine\",\n",
    "                                       retriever=retriever,\n",
    "                                       return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "fac76b7d-e4f9-47cf-a4e9-edbfd617774e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "01bd466e-5d94-41fc-bad2-f92cb5640d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pando has raised a total of $45 million in funding, with $30 million coming from its Series B round. The company plans to use these funds to expand its sales, marketing, and delivery capabilities, as well as to explore strategic partnerships and acquisitions. Pando's software-as-a-service platform aims to revolutionize the digital logistics market, which is projected to reach $46.5 billion by 2025. The company has experienced significant growth since its Series A funding in 2020, with revenue increasing 8x and the customer base expanding 5x. According to co-founder Jayakrishnan, Pando has a strong balance sheet and profit and loss statement, and is focused on profitable growth. The company is scaling operations in North America, Europe, and India, and has already secured marquee customer wins and a network of strong partners. Overall, Pando is well-positioned to drive supply chain agility for the 2030 economy.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"How much money did Pando raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "2d90a2c4-c1a0-45c8-bc5b-14b9bb889668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The news is that Pando, a global logistics company, has secured new funding to expand its operations and enhance its capabilities in supply chain management. This funding will also be used to develop its no-code capabilities and machine learning algorithms, as well as integrate with leading enterprise resource planning (ERP) systems. Pando's platform also has the ability to detect anomalies and anticipate supply chain risks, making it a strong competitor in the digital logistics market. With a growing list of notable customers and a strong financial standing, Pando is well-positioned to capitalize on the increasing demand for supply chain visibility and management tools.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "# break it down\n",
    "query = \"What is the news about Pando?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)\n",
    "# llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e7fd6108-c894-40b0-bb81-5bb8872cb165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Iron Pillar and Uncorrelated Ventures led the $30 million Series B funding round in Pando, with participation from other investors. This brings Pando's total funding to $45 million. The company plans to use the funds to expand its sales, marketing, and delivery capabilities. Pando offers a software-as-a-service platform that consolidates supply chain data and provides tools for freight procurement, trade management, and more. The platform differentiates itself with its no-code capabilities and integration with leading enterprise resource planning systems. Pando has seen significant growth since its Series A funding in 2020, with revenue increasing 8x and the customer base expanding 5x. The company aims to capitalize on the growing digital logistics market, which is estimated to reach $46.5 billion by 2025. According to Pando's CEO, the company has a strong financial position and is focused on profitable growth. They have already achieved success with marquee customer wins and a network of strong partners, and plan to expand their operations in North America, Europe, and India. Overall, Pando is well-positioned to take advantage of the growing digital logistics market and drive supply chain agility for the 2030 economy.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
      "new_articles\\05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"Who led the round in Pando?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f52d1fe3-0ffd-485c-9570-2850070b38c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Databricks announced the acquisition of Okera, a data governance platform with a focus on AI, for an undisclosed amount. Okera had previously raised nearly $30 million from investors such as Felicis, Bessemer Venture Partners, Cyber Mentor Fund, ClearSky, and Emergent Ventures. As part of the acquisition, Okera co-founder and CEO Nong Li joined Databricks, bringing his expertise in data storage and governance, including creating the Apache Parquet data storage format and working at Cloudera. This acquisition will allow Databricks to integrate Okera's secure and scalable governance solutions into their offerings, providing a modern, AI-centric governance solution for enterprises dealing with large volumes of data. Li's involvement in the integration process is expected to enhance Databricks' capabilities and bring more value to its customers.\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles\\05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
      "new_articles\\05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
      "new_articles\\05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
      "new_articles\\05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n",
      "new_articles\\05-03-databricks-acquires-ai-centric-data-governance-platform-okera.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What did databricks acquire?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "9d56d870-655c-49a9-a204-8e33083831fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generative AI is a technology that uses machine learning algorithms to generate new content, such as art, music, or text, based on patterns and data it has been trained on. It has gained attention for its ability to create realistic and coherent outputs. One popular example of generative AI is ChatGPT, an AI-powered chatbot developed by OpenAI. ChatGPT uses the latest language-writing model, GPT-4, and has introduced plugins that allow access to external knowledge sources. However, there have been concerns about potential misuse of ChatGPT, such as the rise of malware posing as the chatbot and its potential use for fraud. There have also been ethical and legal issues raised, such as data privacy and plagiarism. Additionally, there have been recent legal disputes over the use of copyrighted data, particularly art, in training generative AI models. To address this, the startup Spawning AI has developed a website, HaveIBeenTrained, which allows creators to opt out of having their work used in the training of specific generative AI models. Spawning AI recently raised $3 million in funding to continue developing standards for consent and control over the use of artwork in generative AI. This highlights the growing importance of ethical considerations in the development and use\n",
      "\n",
      "\n",
      "Sources:\n",
      "new_articles\\05-03-spawning-lays-out-its-plans-for-letting-creators-opt-out-of-generative-ai-training.txt\n",
      "new_articles\\05-03-ai-replace-tv-writers-strike.txt\n",
      "new_articles\\05-03-spawning-lays-out-its-plans-for-letting-creators-opt-out-of-generative-ai-training.txt\n",
      "new_articles\\05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt\n",
      "new_articles\\05-03-spawning-lays-out-its-plans-for-letting-creators-opt-out-of-generative-ai-training.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What is generative ai?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d836e-9c43-47cf-870d-6249a298eb88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
