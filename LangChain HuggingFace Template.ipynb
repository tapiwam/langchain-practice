{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24df58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub\n",
    "# !pip install transformers\n",
    "# !pip install text_generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "938556af-541a-4286-bf98-ef139125a078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Schema for chat\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Prompt import fro llm and chat\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# Caching\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9faf781b-16dd-4f62-9922-82ee6940461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheType = 'in_memory'\n",
    "\n",
    "if cacheType == 'in_memory':\n",
    "    set_llm_cache(InMemoryCache())\n",
    "elif cacheType == 'sqlite':\n",
    "    set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dadb86a6-64c8-4f9d-9a67-13368fd9d107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = open('./hf_key.txt').read()\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52b10f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"google/flan-t5-xxl\"  # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
    "model_kwargs = {\"temperature\": 0.5, \"max_length\": 64}\n",
    "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab49119-15b2-47bb-910a-6f99ef888de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Who won the FIFA World Cup in the year 1994? \"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a28141e-5ead-44e4-8874-04ad7d672462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1994 FIFA World Cup was won by France. The answer: France.\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21319519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
