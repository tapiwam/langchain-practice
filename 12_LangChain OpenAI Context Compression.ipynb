{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64959efd",
   "metadata": {},
   "source": [
    "# Lanchain OpenAI Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "938556af-541a-4286-bf98-ef139125a078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import langchain\n",
    "import os\n",
    "import logging\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Import chat templates\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# Caching\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9faf781b-16dd-4f62-9922-82ee6940461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheType = 'in_memory'\n",
    "\n",
    "if cacheType == 'in_memory':\n",
    "    set_llm_cache(InMemoryCache())\n",
    "elif cacheType == 'sqlite':\n",
    "    set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "# Set OpenAI API key and create LLM and Chat LLM. Note that key can be stored in a separate file or as an environment variable. Refer to docs.\n",
    "api_key = open('./openai_key.txt').read()\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "logging.basicConfig(filename='example.log', encoding='utf-8', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41982e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8bf03ec-78d6-451f-ae93-1401acce5602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "516fbba0-af3c-41ad-bfd3-36d7918d1d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "def load_file_into_db(file, db_name,embedding_function, chunk_size=500): \n",
    "    logging.info(f'Loading file into DB. file={file} db={db_name}, chunk_size={chunk_size}')\n",
    "    loader = TextLoader(file)\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    db = Chroma.from_documents(docs, embedding_function, persist_directory=db_name)\n",
    "    \n",
    "    # save to disk\n",
    "    db.persist()\n",
    "    logging.info(f'Persited file into DB. file={file} db={db_name}, chunk_size={chunk_size}')\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab49119-15b2-47bb-910a-6f99ef888de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddings()\n",
    "db_connection = Chroma(persist_directory=db_path, embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a28141e-5ead-44e4-8874-04ad7d672462",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = './speech_new_db_1'\n",
    "question = \"What was Lincon's stance on slavery?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04405adb-a03b-4ff1-8985-c13ca2e68fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x241bce2b9d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = load_file_into_db('extras/01-Data-Connections/some_data/FDR_State_of_Union_1944.txt',\n",
    "                    db_path, embedding_function, chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e912dc3-5f6b-490e-ad44-f71c8be0a80e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.text_splitter:Created a chunk of size 611, which is longer than the specified 500\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 539, which is longer than the specified 500\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 686, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "db = load_file_into_db('extras/01-Data-Connections/some_data/Lincoln_State_of_Union_1862.txt',\n",
    "                    db_path, embedding_function, chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4703188b-af93-42c4-8dea-d5e1c09afcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Use compression\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "# LLM -> LLMChainExtractor\n",
    "compressor = LLMChainExtractor.from_llm(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8585f4d4-fd1f-4c4f-86a2-a824332eb24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Context Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor,\n",
    "                                                       base_retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "964b0b63-4638-4a96-9a37-c04f62176e64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Among the friends of the Union there is great diversity of sentiment and of policy in regard to slavery and the African race amongst us. Some would perpetuate slavery; some would abolish it suddenly and without compensation; some would abolish it gradually and with compensation: some would remove the freed people from us, and some would retain them with us; and there are yet other minor diversities. Because of these diversities we waste much strength in struggles among ourselves. By mutual conce'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Old way without OpenAI\n",
    "docs = db_connection.similarity_search(question)\n",
    "docs[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f60ea83-da9c-41bb-ad45-1efca691656c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# New way with context retriever\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be656207-9e2a-4822-a5a0-3c1113fccf0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Some would perpetuate slavery; some would abolish it suddenly and without compensation; some would abolish it gradually and with compensation: some would remove the freed people from us, and some would retain them with us; and there are yet other minor diversities. Because of these diversities we waste much strength in struggles among ourselves. By mutual concession we should harmonize and act together. This would be compromise, but it would be compromise among the friends and not with the enemies of the Union. These articles are intended to embody a plan of such mutual concessions. if the plan shall be adopted, it is assumed that emancipation will follow, at least in several of the States.', metadata={'source': 'extras/01-Data-Connections/some_data/Lincoln_State_of_Union_1862.txt'})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6fda8-d965-4c10-aa13-980bf14334c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
